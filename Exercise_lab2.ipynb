{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab88d307-61ba-45ef-89bc-e3569443dfca",
   "metadata": {},
   "source": [
    "# Chapter 2 - Lab 1a - Exercise\n",
    "> Author : Badr TAJINI - Large Language model (LLMs) - ESIEE 2024-2025\n",
    "\n",
    "> Response by Paul CASCARINO E5-DSIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f678e62-7bcb-4405-86ae-dce94f494303",
   "metadata": {},
   "source": [
    "# Exercise 2.1\n",
    "\n",
    "### Exploring Byte Pair Encoding (BPE) Tokenization with Unknown Words\n",
    "\n",
    "#### 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d743b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Input\n",
    "input_txt = \"Akwirw ier\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ad189",
   "metadata": {},
   "source": [
    "#### 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf8b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33901, 86, 343, 86, 220, 959]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the tiktoken BPE Tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\") # I use the gpt2 like the lab.2\n",
    "\n",
    "# Tokenizing input text with tiktoken\n",
    "token_ids = tokenizer.encode(input_txt)\n",
    "\n",
    "\n",
    "# Print the token IDs generated for this input.\n",
    "print(token_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0a502",
   "metadata": {},
   "source": [
    "#### 2. Subword Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c73c5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ak', 'w', 'ir', 'w', ' ', 'ier']\n"
     ]
    }
   ],
   "source": [
    "# For each token ID in the resulting list, use the tokenizer's `decode` function to convert the ID back \n",
    "# into its corresponding subword or character.\n",
    "decoded_tokens = [tokenizer.decode([token_id]) for token_id in token_ids]\n",
    "\n",
    "print(decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b09aaf",
   "metadata": {},
   "source": [
    "#### 3. Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4466d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akwirw ier\n"
     ]
    }
   ],
   "source": [
    "# Apply the `decode` method to the entire list of token IDs\n",
    "reconstructed_txt = tokenizer.decode(token_ids)\n",
    "\n",
    "print(reconstructed_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b4392",
   "metadata": {},
   "source": [
    "### Questions - Exercise 2.1\n",
    "1. What sequence of token IDs does the BPE tokenizer generate for the input **\"Akwirw ier\"?**\n",
    "2. What subwords or characters correspond to each token ID in the sequence?\n",
    "3. Does the reconstructed output from the token IDs match the original input? Explain your observations and reasoning.\n",
    "\n",
    "### Responses - Exercise 2.1\n",
    "\n",
    "1. [33901, 86, 343, 86, 220, 959]\n",
    "2. \n",
    " - 33901: 'Ak'\n",
    " - 86: 'w'\n",
    " - 343: 'ir'\n",
    " - 86: 'w'\n",
    " - 220: ' ' \n",
    " - 959: 'ier'\n",
    "3. The reconstructed output from the token IDs match the original input (\"Akwirw ier\") because the tokenizer encodes the input without losing information. Our BPE tokenizer recognize subwords, character and space well so we can reconstruct the entire input text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5034a-95ed-46d8-9972-589354dc9fd4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 2.2\n",
    "\n",
    "###  Exploring Data Loader Behavior with Different Parameter Configurations\n",
    "\n",
    "#### 0. Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d2a3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Importing Required Modules\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Defining the Custom Dataset Class\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "\n",
    "\n",
    "# Creating the Data Loader Function\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b48346b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cfe708",
   "metadata": {},
   "source": [
    "#### 1. Experimenting with `max_length` and `stride`\n",
    "\n",
    "##### 1.1 max_length=2 and stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b36c100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[ 40, 367]])\n",
      "\n",
      "Targets:\n",
      " tensor([[ 367, 2885]])\n"
     ]
    }
   ],
   "source": [
    "max_length = 2\n",
    "stride = 2\n",
    "\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=max_length, stride=stride, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3898f",
   "metadata": {},
   "source": [
    "##### 1.2 max_length=8 and stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4785665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[  40,  367, 2885, 1464, 1807, 3619,  402,  271]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])\n"
     ]
    }
   ],
   "source": [
    "max_length = 8\n",
    "stride = 2\n",
    "\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=max_length, stride=stride, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9cfa6",
   "metadata": {},
   "source": [
    "They differ because, with max_length=2, the model processes short chunks and focuses on immediate relationships between tokens, whereas with max_length=8, the model captures a broader context in each input-output pair.\n",
    "\n",
    "#### 2. Increasing Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f8524a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=4, stride=4,\n",
    "    shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac9ece",
   "metadata": {},
   "source": [
    "When increasing the batch size to 8, the inputs tensor contains multiple sequences (each of max_length=4), and the corresponding targets tensor is shifted by one token position for each sequence. This batching allows the model to process multiple sequences simultaneously, improving computational efficiency while maintaining the sequential structure for each input-target pair.\n",
    "\n",
    "#### 3. Avoiding Overlap\n",
    "\n",
    "Find on the lab : *\" Adjusting the stride parameter affects the overlap between input sequences. By setting stride equal to max_length, overlapping is minimized, which can help prevent overfitting.\"*\n",
    "\n",
    "Using stride=4 ensures that there is no overlap between consecutive sequences in the input. Each sequence starts exactly where the previous one ends, thereby avoiding repetition of tokens across input-output pairs. This configuration minimizes redundancy in the data, reduces the risk of overfitting caused by repeated exposure to overlapping sequences, and promotes diverse training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cb84a",
   "metadata": {},
   "source": [
    "### Questions - Exercise 2.2\n",
    "1. How do changes in `max_length` and `stride` affect the input-output mappings produced by the data loader?  \n",
    "2. What differences do you observe in the data when using a batch size of 8 compared to a batch size of 1?  \n",
    "3. How does using a larger stride (e.g., `stride=4`) influence the coverage of the dataset and the overlap between sequences?  \n",
    "\n",
    "### Responses - Exercise 2.2\n",
    "\n",
    "1. Increasing max_length increases the context captured within each sequence, allowing the model to learn from longer dependencies, while increasing stride reduces the overlap between sequences, minimizing redundancy and promoting unique training examples.\n",
    "\n",
    "2. Using a batch size of 8 processes multiple sequences simultaneously, improving computational efficiency compared to a batch size of 1, which processes sequences individually.\n",
    "\n",
    "3. A larger stride, such as stride=4 (if max_length=4), ensures no overlap between sequences, reducing redundancy while covering more unique parts of the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
